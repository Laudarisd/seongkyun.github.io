---
layout: post
title: L1 & L2 loss
category: study
tags: [L1 loss, L2 loss]
comments: true
---

# L1 & L2 loss

참고 글: https://www.stand-firm-peter.me/2018/09/24/l1l2/

- L1, L2 loss라고도 하고 L1, L2 Regularization이라고도 한다.
  - 두 가지 목적으로 사용되어진다.
  
## As an Error Function
- 모델의 Loss를 구하는 방법으로 L1, L2 loss가 사용될 때 아래의 식을 따른다.

### L1 loss
- L1 loss를 보면, 식처럼 실제 값 $y_{i}$와 예측값 $f(x_{i})$ 사이의 차이값에 절댓값을 취해 그 오차 합을 최소화하는 방향으로 loss를 구한다.
- Least Absolute Deviations, LAD라고도 한다.

$$L=\sum_{i=1}^{n}|y_{i}-f(x_{i})|$$

### L2 loss
- L2 loss는 MSE(Mean Square Error)를 안다면 아주 익숙한 개념으로 target value인 실제값 $y_{i}$와 예측값 $f(x_{i})$ 사이의 오차를 제곱한 값들을 모두 합하여 loss로 계산한다.
- Least square error, LSE라고도 한다.

$$L=\sum_{i=1}^{n}(y_{i}-f(x_{i}))^{2}$$

## L1 loss와 L2 loss의 비교
- L1, L2 loss는 아래와 같은 차이점을 갖는다.

### 1. Robustness:
#### L1>L2
- Robustness는 outlier, 즉 이상치가 등장했을 때 loss function이 얼마나 영향을 받는지를 뜻하는 용어
- L2 loss는 outlier의 정도가 심하면 심할수록 직관적으로 제곱을 하기에 계산된 값이 L1보다는 더 큰 수치로 작용하기때문에 Robustness가 L1보다 적게된다.
  - 제곱의 합이므로 당연히 더해진 값이 더 크다.
- 따라서 outliers가 효과적으로 적당히 무시되길 원한다면 비교적 이상치의 영향력을 작게 받는 L1 loss를, 반대로 이상치의 등장에 주의 깊게 주목을 해야할 필요가 있는 경우라면 L2 loss를 취하여야 한다.

### 2. Stability
#### L1<L2
- Stability는 모델이 비슷한 데이터에 대해 얼마나 일관적인 예측을 할 수 있는가로 생각하면 된다. 이해를 위해 아래의 그림을 보자.

<center>
<figure>
<img src="/assets/post_img/study/2019-04-18-l1_l2/fig1.gif" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 위 그림에서 실제 데이터는 검은 점으로 나타난다.
- 위 그림에서 실제 데이터(검은점)와 Outlier point인 주황색 화살표의 점이 움직임에 따라 어떻게 각 L1과 L2에 따라 예측 모델이 달라지는지를 실험해 본 결과이다.
- Outlier point가 검은 점들에 비교적 비슷한 위치에 존재할 때 L1 loss 그래프는 변화가 있고 움직이지만, L2 loss 그래프에는 그러한 변화가 없다. 이러한 특성때문에 L1이 L2보다는 unstable하다고 표현한다.
- 위 그림에서 또한 robustness도 관찰 가능한데, outlier point가 검은점들의 경향성이 이어지는 선을 기준으로 왼쪽이서 오른쪽으로 이동할 때 L2 error line이 L1보다 더 먼저 움직이는것을 확인 할 수 있다.
  - 즉, L1보다 L2가 먼저 반응하므로 L1이 robust하고, outlier의 움직임에 L2보다 L1이 더 많이 움직이기에 L2가 stable하다.
  


<center>
<figure>
<img src="/assets/post_img/study/2019-04-18-l1_l2/fig1.png" alt="views">
<figcaption></figcaption>
</figure>
</center>
