---
layout: post
title: 자율주행 자동차에 대해서
category: study
tags: [자율주행, Autonomous driving]
comments: true
---

# 자율주행 자동차에 대해서
- 자율주행 자동차란?
  - 자동차관리법 제 2조 제 1호의 3항에 따라 "승객의 조작 없이 자동차 스스로 운행이 가능한 자동차"를 의미함
  - 즉, 운전자의 핸들, 가속페달, 브레이크 조절이 필요없이 정밀지도와 각종 센서를 이용해 상황을 파악하고 스스로 목적지까지 움직여주는 자동차

### 자율주행의 필요성
- 인적요인으로 발생하는 교통사고(90% 이상)를 방지
  - 음주, 과속, 피로누적 등등..
  - 전 세계적으로 매년 125만명의 사람이 운전자 과실로 인한 교통사고로 사망
  - 자율주행을 적용해 이러한 인적요인을 제거
- 안전한 차간거리 유지, 적절한 속도 관리로 정체를 발생시킬 수 있는 요소를 차단해 교통의 효율화 가능
- 고령 운전자 및 장애인을 위해 필요
- 운전의 효율화
- 정리하자면
  - 안전성: 인적요인에 의한 사고 감소
  - 효율성 및 친환경성: 교통체증 완화, 운전의 효율화를 통한 환경오염 감소
  - 편의성: 사용자의 편의성 향상
  - 사회적 수용성: 노약자의 이동성 향상
  - 접근성: 도시 주요부로의 접근성 향상

## 자율주행 기술
### 자율주행 단계
- 자동차기술자협회(SAE)의 5단계와 미국도로교통안전국(NHTSA)의 4단계가 존재
- SAE 기준
  - 0단계: 자동제어 장치 없이 일반적으로 사람이 운전
  - 1단계: Foot off. 자동긴급제동장치(AEB), 어뎁티브 크루즈 컨트롤(ACC), 핸들 조향 지원 및 자동보조시스템 등의 적용
  - 2단계: Hands off. 핸들 방향 조종 및 가감속 등 하나 이상의 첨단운전자보조시스템(ADAS) 적용
  - 3단계: Eye off. 자율주행으로 정의되는 단계. 가속, 주행, 제동이 모두 자동으로 수행되나 특정 상황시 운전자의 개입이 필요한 조건부 자동화 단계
  - 4단계: Head off. 시내주행을 포함한 도로 환경에서 운전자의 개입이나 모니터링이 필요 없는 자율주행. 고도의 자동화 단계
  - 5단계: Driver off. 완벽한 자율주행 수준. 모든 환경하에 운전자의 개입 없이 자율주행이 가능한 완전 자동화 단계

### 자율주행차의 주요 요소
- 주요 기술로는 __환경 인식, 위치인식 및 맵핑, 판단, 제어, HCI__ 로 나뉨
  - 환경 인식: 레이더, 라이다, 카메라, 초음파 센서 등의 각종 센서로 정적 장애물(가로등, 건물, 전봇대 등)과 동적 장애물(차량, 보행자 등), 도로 표식(차선, 신호, 횡단보도 등)을 인식하고, V2X통신을 통해 도로 인프라 및 주변 차량과 주행정보를 교환
  - 위치인식 및 맵핑: GPS, INS, Encoder, 기타 맵핑을 위한 센서를 사용. 자동차의 절대/상대 위치를 계산
  - 판단: 목적지 이동, 장애물 회피 경로 계획, 주행상황별(신호등 처리, 차선유지 및 변경, 회전, 추월, 유턴, 급정지, 끼어들기, 주정차 등) 행동을 스스로 판단
  - 제어: 운전자가 지정한 경로대로 주행하기 위해 차량의 조향, 속도 변경, 기어 등의 엑츄에이터 제어
  - HCI: Human Computer Interaction. 주로 HMI(Human Machine Interaction)으로 정의됨. 운전자에게 경고 또는 정보를 제공하고 운전자의 명령을 입력받음
- 자율주행의 메커니즘
  - 주행 주변 환경에 대한 각종 정보를 센서들을 이용해 수집하는 단계
  - 센서를 통해 수집된 정보들을 처리하고 차량을 통제하는 알고리즘 단계
  - 알고리즘을 실시간으로 처리하는 전산처리 단계
- 시스템적 요소는 인지, 판단, 제어로 나뉨
  - 인지: 자동차의 센서들이 차량 주변에 대한 데이터를 수집
    - 경로탐색: 고정밀 디지털 지도
    - 센서: 카메라, 레이더, 라이다 등
    - V2X: V2V, V2I 등의 통신
  - 판단: 수집된 데이터를 소프트웨어 알고리즘으로 분석/해석
    - 경로탐색: 차량의 절대적, 상대적 좌표, 3D 지도정보
    - 센서: 차량 주변의 장애물, 도로 표식, 신호
    - V2X:도로의 인프라 및 주변차량 정보
    - 위의 정보들을 취합해 목적지까지의 주행 경로 설정, 돌발상황에 대한 판단과 주행 전략 등을 결정
  - 제어: 앞 단계에서 취합된 정보들을 바탕으로 운행 계획에 따라 자동차의 동작을 제어
    - 차량 제어
    - 조향 조절, 엔진 가/감속
    - 운전자에게 경고 및 정보 제공
- 자율주행차 주요 기술 구성
  - 자율주행 차량의 센싱
    - 레이더, 라이다, 레이저 센서
    - HD급의 vision camera
    - 적외선/자외선 센서
    - 환경 센서
  - 자율주행 소프트웨어  
    - 주행상황 인지 소프트웨어
    - 센싱 융합처리 드라이빙 컴퓨팅
    - 인공지능(AI)기반 컴퓨팅
    - 클라우드 기반 컴퓨팅
  - 통신보안
    - 차량 무선통신 시스템
    - 협력주행 네트워킹
    - 이동통신망 연동 네트워킹
    - V2V, V2I(infra) 정보보호 및 보안
    - 통신 이상징후 탐지
  - 안전운전
    - 교통약자 안전운전 지원 HMI
    - 운전자 케어 UI/UX
    - 다중 차량 무선충전
    - 인포테인먼트
- 자율주행 소프트웨어 구조
  - Cloud map, GPS, INS/IMU, Vehicle State, Lidar 등을 이용한 Localization (Map matching)
  - Lidar, Camera 등의 센서에서 얻어진 정보들을 이용해 Object detecion, tracking, Lane detection 등을 수행
  - 위의 결과들과 RNDF, Traffic light information을 토대로 Navigation 
    - Global/local path planning, Path following, Speed planning
  - Navigation 결과를 VCU(Vehicle Control Unit)로 전달
    - Steering, Brake, Acceleration

### 자율주행 주요 기술
- 컴퓨터 플랫폼: Nvidia Drive PX2, Xavier, Mobileye EyeQ, TI TDA 3X 등의 인공지능 플랫폼
- V2X 통신: C-ITS, 5G, WAVE(도로 인프라 및 주변차량 정보 수집/취합)
- 보안: 전장 플랫폼 보안, 내/외부 네트워크 보안, KMS(암복호화 키 관리 시스템), AFW(어플리케이션 방화벽)
- AI: 강화학습, 딥러닝 학습
  - 인지: 차선, 보행자, 차량 검출등의 Object detection
  - 판단: 의도 판단, 경로 예측
  - 제어: 사용자 개인화 기반 최적 제어

### 자율주행 차량의 센서
- 주로 인지를 위해 사용
- 핵심센서는 다음과 같음
  - 카메라: 대상 물체에 대한 형태 정보를 제공하며 차선, 표지판, 신호등, 차량, 보행자 등을 탐지하기 위한 정보를 센싱
  - 라이다: 레이저를 이용해 현재위치부터 목표물까지의 거리, 방향, 속도, 온도 등의 특성을 감지하며 전파에 가까운 성질을 가진 레이터 광선을 이용하여 활용가능범위가 매우 넓음
  - 레이다: 전자기파를 발사해 반사 신호 분석을 통해 거리, 높이, 방향, 속도 등 주변정보를 습득
- 센서들은 외적인 요인들로 인해 클리닝 문제, 내구성 문제 등이 발생 할 수 있기 때문에 해당 문제 또한 중요함
  - 정상적인 자율주행을 위해선 최적 상태의 센서가 유지되어야 함

<center>
<figure>
<img src="/assets/post_img/study/2019-10-30-autonomous_car/fig1.jpg" alt="views">
<figcaption>현대자동차 넥쏘에 적용 센서들</figcaption>
</figure>
</center>

#### 카메라

<center>
<figure>
<img src="/assets/post_img/study/2019-10-30-autonomous_car/fig2.jpg" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 장점
  - 스테레오 카메라를 이용해 얻어진 영상에 양안시차의 원리를 적용하여 객체와의 거리를 계산하고 어떤 객체인지 종류도 분류 가능
    - Object detection
  - 비교적 먼 거리를 볼 수 있으며, 시야 내의 모든 정보를 센싱 가능
  - 다른 센서에 비해 월등히 저렴함
- 단점
  - 시스템의 분석능력이 아직 정확하지 않음
    - 딥러닝 모델등을 이용해 극복 가능
  - 사람의 눈과 같은 메커니즘으로 악천후 등의 기상상황에서 주변환경을 인지함에 있어 매우 불리함
    - 센서 퓨전을 통해 극복 가능
- 현재 모빌아이의 자율주행 시스템이 카메라를 중심적으로 활용하고 있음
  - 테슬라가 사용했었음 (현재는 NVIDIA)

#### 라이다(Lidar)
- 자율주행차량의 센서 중 객체 감지에 잇어 핵심이 되는 센서
- 주변 환경에 레이저를 조사하고, 반사된 레이저광이 센싱될 때 까지의 시간을 측정해 비교적 정확하게 주변 사물과의 거리를 측정 할 수 있음
  - 이를 통해 SLAM의 기반이 되는 맵을 생성 할 수 있음
- 실시간으로 주변 환경에 대한 3차원 데이터를 수집해 도심과 같이 수많은 객체가 존재하고 움직이는 환경에서 매우 중요한 역할을 함
- 하지만 가격이 비싸고 특정 재질에 대한 반사도가 낮기때문에 고도의 데이터 처리 능력이 필요하다는 단점이 있음
  - 제사한 사항은 후술

#### 레이더(Radar)
- 라이다처럼 주변에 신호를 보내 반사된 신호의 시간을 측정해 거리를 탐지하는 센서
- 레이저를 사용하는 라이다와 다르게 라디오 주파수를 사용함
  - 이로인해 유효 감지거리가 라이다에 비해 길고 라이다보다 손쉽게 주변 차량의 상대속도 등을 측정 할 수 있음
    - ACC(Adaptive Cruise Control)과 같은 차량 보조 시스템에서 사용됨
- 하지만 반사성을 갖는 재질만 탐지 가능하기 때문에 금속 이외의 물체 탐색이 어려운 단점이 있음
  - 일반적인 상황에서 사람을 찾을 수 없음
- 이로인해 레이더 단독으로 자율주행 구현이 불가능하며, 센서퓨전을 통해 단점을 보완해야 함

#### 초음파 센서
- 1~10m 거리 내의 사물에 대한 탐지 능력이 우수하며 상대적으로 저렴
  - 주로 주차 보조 시스템에 많이 활용됨

#### 적외선 센서
- 주변에 조명이 없는 경우 적외선을 조사해 반사된 적외선을 통해 적외선 영상정보를 획득 할 수 잇음
- 악천후 상황 속에서도 객체 감지가 가능함
- 야간에도 보행자와 자전거 등 사람 및 사물등의 감지가 가능
- 하지만 탐지 가능 거리가 짧아 보조 센서의 역할로만 사용됨

- 외에도 다양한 센서 관련 내용이 있지만 이는 후술

#### 센서 퓨전
- 자율주행의 레벨이 높아짐에 따라 여러 센서를 퓨전하여 사용하는 방법들이 제시됨
- 어느 센서로 들어온 데이터를 중심으로 전반적인 데이터 취합을 하느냐에 따라 방법이 나뉨
  - LIDAR와 GPS를 이용해 구성된 맵데이터를 보조적으로, 카메라로 획득된 정보를 주로 사용하는 Incremental approach
    - Tesla, GM, Ford, Volvo 등의 주요 OEM
    - 가성비가 매우 높으며, 하드웨어 복잡도가 낮음. 또한 맵에 대한 의존도도 낮기때문에 Robust한 장점이 있음
    - 반면 높은 수준의 센서 퓨전 기술이 필요하고, 딥러닝 기반으로 동작해야 하기 때문에 고성능 하드웨어 프로세서 필요(가격상승요소)
  - LIDAR와 GPS를 이용해 구성된 맵데이터를 주로, 카메라로 획득된 정보를 보조적으로 사용하는 Disruptive approach
    - Google
    - 맵 구성에 필요한 자원을 아낄 수 있어 경쟁성이 있음
    - 반면 대량의 지도 데이터를 확보하지 않은 상태에선 자율주행의 동작이 불가하며 라이다 가격이 매우 비쌈. 또한 회전하는 기계식 라이다 채용으로 인해 디자인적 요소가 훼손됨

### V2X
- 위급상황과 같은 안정성 제고를 위한 필수적인 시스템으로 차량의 고속주행 속에서도 높은 패킷전송률과 낮은 지연율을 요구하는 기술
  - 5G 통신의 보급으로 해결
- 카메라 등의 다양한 센서들과 다르게 악천후 조건에서도 무리없이 통신 가능하기 때문에 안정성을 높여주는 역할로 주로 적용

### 고정밀 위치 측위
- GPS의 경우 거리적 오차가 크고, 서울과 같은 도심에서는 위성 신호가 반사되어 신호 포착이 어렵기 때문에 자율주행에는 고정밀 디지털 지도가 필수적으로 필요함
- 도로의 모든 정적정보를 3차원으로 표현한 고정밀 디지털지도를 통해 도로에 위치하고 있는 물체의 위치, 형태 등의 정보를 얻을 수 있음
- 이를 이용해 곡선로, 교차로 합류와 같은 어려운 상황에 쉽게 사전 대응이 가능

### 인공지능
- 차량에 탑재된 센서들과 V2X를 통해 습득된 교통, 도로 정보들을 분석하고 자체적인 판단을 통해 차량을 제어
- 차량을 운행하는 과정 중 지속적으로 제공되는 광범위한 정보를 빠르게 처리하고 판단
- 인공지능의 자율주행 적용엔 __강화학습__ 방법과 __End-to-end__ 방법이 있음
  - 강화학습: 주행 데이터 확보의 제약으로 충분한 학습이 어려운 분야에 적용되는 방법으로, 사람의 개입이 없어도 반복 학습을 통해 인공지능이 스스로 목적을 달성하는 과정을 터득
  - End-to-end: 차량의 카메라 정보와 조향 정보를 사전에 학습용 데이터셋으로 쌓고, 이를 기반으로 특정 상황에 대한 주행 방법 및 알고리즘을 딥러닝 모델이 스스로 학습

- Drive.ai는 타 업체와는 다르게 딥러닝 시스템을 인지 센서 뿐만 아니라 동작 프로세스까지 확대하여 적용
  - 타 업체의 경우 사전에 취득된 차량 센서 데이터(영상 등)을 사전 주석작업을 통해 GT를 만들고 이를 인지 학습시켜 인지 과정에서만 딥러닝을 적용
  - Drive.ai는 주행 자체를 주행 시나리오로 학습시켜 전반적인 주행 과정을 차량이 학습하여 자율주행을 구현토록 함

#### 객체 탐지
- 시내주행 상황
  - 차량 존재여부, 거리, 상대속도 정보 획득
    - 차종을 통해 운전자의 성격, 주행 습관 등 예측 및 추측 가능
  - 표지판 인식
    - 내용 인식 후 주의
  - 사람 인식
    - 어른과 아이를 인식하고, 아이의 돌발행동 대비 가능
  - 바람부는 상황 등 인식
    - 강풍으로 인해 무언가 날아 올 수 있을 수 있는 상황에 대비 가능
- 고속도로주행 상황
  - 차량 존재여부, 거리, 상대속도 정보 획득
    - 차종 분석을 통해 운전자의 성격, 행동 예측 가능
    - 트럭 등의 선행차량 탐지를 통해 상대속도를 예측하고, 주변 차량의 주행차량 앞으로 끼어들기 등의 상황 예측 가능
  - 차선 인식
    - 노면 상태 및 차선 인식 가능
- 정체도로 상황
  - 차량 인식
    - 선행차량의 상대속도 탐지를 통해 차선변경 시 빠르게 갈 수 있는지 여부 등을 판단
    - 트럭 등의 인식을 통해 주변 차량의 차선변경 등 예측 가능
- 날씨변화 상황
  - 노면 인식
    - 노면이 젖어있는지, 얼어있는지 등을 인식
    - 결과를 토대로 안전을 위한 예측운전 등 가능

- 객체 탐지를 통해 보행자의 움직임, 차량 진행 방향, 도로인지 차도인지 등과 같은 문맥적 의미(Context awareness)를 이해 할 수 있음

## 딥러닝 학습 지능의 적용
- 기존의 규칙기반 방식(Rule-based approach)은 몇 가지 한계점이 존재
  - 산업 내 전문성을 갖춘 인력들을 영입하고 오랜 시간에 걸쳐 정교하게 규칙들을 모델링 해야 하기에 매우 비효율적
    - 또한 실제 상황에 지속적으로 적용하며 테스트를 반복해 검증하는 과정이 필요함
  - 확장성이 매우 떨어짐
    - 정교하게 모델링된 규칙을 만들었다고 하더라도 주행 규칙이 다른 국가에 적용하거나 기후적/지역적 주행환경이 다른 지역에 바로 적용하는것이 매무 어려움
    - 이 경우 만들어진 모델을 새로운 환경에 맞게 재조정하는 과정이 필요하며, 또한 시간이 많이 소요되는 검증과정이 필요함
  - 아무리 정교하게 만들어진 규칙이라 할지라도 주행 중 발생 가능한 모든 상황을 사전에 반영하는것은 불가능
- 특화 센서+전문가 중심 구현
  - BOSCH, Google, Continental 등(2009년 개발 초기)
- 범용 센서+딥러닝 중심 구현
  - comma.ai, drive.ai
  - 최소의 범용센서를 사용해 딥러닝을 통해 기능 구현
- 카메라+딥러닝 중심 구현
  - AutoX, NVIDIA, UBER AI Labs
  - 딥러닝 기반의 고도화된 비전 기술을 활용해 기능 구현
- 딥러닝 기반은 인간의 주행과정을 데이터화해 인공지능이 주행 방법을 학습하게 됨
  - 사람이 운전을 반복하며 익숙해져 가능 과정과 유사
  - 인공지능이 주행을 지속할 수록 다양한 상황에서의 대응 방법을 획득하고 터득함
- 강화학습 기반은 반복학습을 통해 인공지능이 다양한 주행 상황별 대응 방법을 스스로 터득하게 됨
  - 수많은 반복 학습 과정을 통해 최적의 대응
  - 방법을 스스로 깨우침
    - 학습 과정에서 일일이 방법을 정의할 필요 없이 상황별 달성 목표와 보상만 정의함
  - 아직은 선행연구단계.(2017년 기준)

### 사람처럼 사고하는 지능의 적용
- 인간처럼 생각하며 주행하는 자율지능 주행을 가능하게 하는 관계형 추론(Relational Reasoning) 모델
  - 주변 상황들을 각각 개별적인 정보로 인식하고 이해하는것을 넘어 정보들 사이의 상대적 관계를 논리적으로 파악
  - 이를 통해 각 사물 사이의 상대적인 관계를 직관적으로 인식 할 수 있음
  - 이는 사람이 운전할 때 주변에 존재하는 차량들 간의 거리를 각각 개별적으로 인식하는것이 아니라 서로간의 상대적 거리와 속도를 종합적으로 인지해 주행하는 것과 마찬가지인 맥락임
  - 사물의 움직이는 패턴을 학습하는 관계형 추론 모델의 적용도 가능
    - 딥마인드 논문으로 화면 내 공들의 움직임을 6프레임만 학습시키면 향 후 150프레임까지 실제와 거의 일치하는 수준으로 예측
- 이러한 관계형 추론 모델을 이용해 상대적 관계를 이해할 경우 급차선변경이나 과속하는 차량의 정보를 토대로 해당 차량의 움직임을 미리 예측해 사고를 사전에 방지하는것 또한 가능해짐    
