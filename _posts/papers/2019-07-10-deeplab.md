---
layout: post
title: DeepLab
category: papers
tags: [Deep learning]
comments: true
---

# DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs

Original paper: https://arxiv.org/pdf/1606.00915.pdf

Authors: Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L. Yuille

- 참고 글
  - https://laonple.blog.me/221000648527

- DeepLab에는 v1과 v2가 있지만, 본 글은 v2에 대해 다루며 앞으로 나오는 DeepLab은 모두 v2이다.
- 논문 제목에 다 나열되어있듯이 Deep convolutional neural networks(DCNN)와 astrous convolution 및 fully connected CRF 개념을 잘 활용해 semantic segmantation을 더 잘하게 되었다. 재미있는건 DeepLab v1에서는 hole algorithm이라는 용어를 사용했으나, v2부턴 atrous convolution으로 바꿔 부른다

## Classification 기반 망을 semantic segmentation에 적용할 때의 문제점
- Classification이나 detection은 기본적으로 대상의 존재 여부에 집중하기에 object-centric하며, 강력한 성능을 발휘하기 위해선 여러 단계의 conv+pooling을 거쳐 말 그대로 영상 속에 존재하며 변화에 영향을 받지 않는(robust하게 영향을 덜 받는) 강인한 feature만을 끄집어내야 함
  - 따라서 details보다는 global 한 것에 집중을해야 함
- 반면 semantic segmentation은 픽셀 단위의 조밀한 예측이 필요한데, classification 망을 기반으로 segmantation망을 구성하게 되면 계속 feature map의 크기가 줄어들기에 detail한 정보를 얻는데 어려움이 있음
- 그래서 FCN 개발자는 skip layer를 사용하여 1/8, 1/16, 1/32 결과를 결합(concat)하여 detail이 줄어드는 문제를 보강하였으며, DeepLab과 앞서 본 dilated convolution 팀(Fisher Yu)은 망의 뒷 단에 있는 2개의 pooling layer를 없애고 dilated conv(atrous conv)를 사용하여 receptive field를 확장시키는 효과를 얻었으며, 1/8 크기까지만 feature map을 줄이도록 하여 detail한 정보들을 보존함
- 하지만 1/8까지만 사용하더라도 다음과 같은 문제가 발생
  - Receptive field가 충분히 크지 않아 다양한 scale에 대응이 어렵다
  - 1/8크기의 정보를 bilinear interpolation을 통해 원 영상 크기로 키우면 1/32 크기를 확장한것보다는 details가 살아있지만 여전히 정교함이 떨어진다
- 이러한 문제를 DeepLab 팀과 dilated convolution 에서는 다른 방식으로 해결하였으며, dilated convolution 팀은 DeepLab 팀의 atrous conv에서 많은 힌트를 얻은 것으로 보여짐

## Atrous convolution
- Atrous conv란 wavelet을 이용한 신호 분석에 사용되던 방식이며, 보다 넓은 scale을 보기 위해 중간에 hole(0)을 채워 넣고 convolution을 수행하는 것을 말함

<center>
<figure>
<img src="/assets/post_img/papers/2019-07-10-deeplab/fig1.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 직관적인 이해를 위해 논문의 1차원 conv 그림을 살펴보면
  - 위 그림 (a)는 기본적인 conv이며, 인접 데이터를 이용해 kernel size 3인 conv를 보여줌
  - (b)는 확장 계수 k가 2인 경우로 인접한 데이터가 아닌 중간에 hole이 1개씩 들어오는 점이 (a)와 차이가 나며, 똑같은 kernel size 3이더라도 대응하는 영역의 크기가 커졌음을 확인 할 수 있음
- 이처럼 atrous conv(dilated conv)를 사용하면 kernel 크기는 동일히 유지하기에 연산량은 동일하지만 receptive field의 크기가 커지는 효과를 얻을 수 있음
- 영상 데이터와같은 2차원에 대해서도 아래와같이 좋은 효과가 있는것을 확인 할 수 있음
  - 자세한 설명은 dilated convolution 참고

<center>
<figure>
<img src="/assets/post_img/papers/2019-07-10-deeplab/fig2.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>

## Atrous convolution 및 bilnear interpolation
- DeepLab v2에선 VGG16뿐만 아니라 ResNet101도 DCNN망으로 사용했으며, ResNet 구조를 변형시킨 모델을 이용해 VGG16모델보다 성능이 더 좋아짐
- DCNN에서 max-pooling layer 2개를 제거함으로 1/8 크기의 feature map을 얻고, atrous conv를 통해 넓은 RF를 갖도록 함
- Pooling 후 동일 크기의 conv를 수행하면 자연스럽게 RF가 넓어짐
- 논문에선 details때문에 pooling layer를 제거하였기에 이 부분을 atrous conv를 사용해 더 넓은 RF를 가질 수 있도록 하였으며, 이를 통해 pooling layer가 사라졌을때의 문제점들을 해소시킴
- 이후FCN이나 dilated conv와 마찬가지로 bilear interpolation을 이용해 원 영상 크기로 복원해냄(아래 그림 참고)

<center>
<figure>
<img src="/assets/post_img/papers/2019-07-10-deeplab/fig3.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>

- Atrous conv는 RF 확대를 통해 입력에서 feature를 찾는 범위를 넓게 해주기 때문에 전체 영상으로 찾는 범위를 확대하면 좋겠지만, 이렇게 하려면 단계적으로 수행을 해야하기에 연산량 증가가 불가피함
- 그래서 이 팀은 적정한 선에서 deal을 했으며, 나머지는 모두 bilinear interpolation을 선택함
- 하지만 bilinear interpolation만으론 정확하게 객체의 픽셀 단위까지 위치를 정교히 segmentation하는게 불가능하므로 뒷부분은 CRF(Conditional Random Field)를 이용하여 post-processing을 수행하도록 함
- 결과적으로 전체적인 구조는 DCNN+CRF의 형태이며, DCNN의 앞부분은 일반적인 conv를, 뒷부분은 atrous conv를 이용했고 전체 구조는 아래와 같음

<center>
<figure>
<img src="/assets/post_img/papers/2019-07-10-deeplab/fig4.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>

## ASPP(Atrous Spatial Pyramid Pooling)
- DeepLab v1과 달리 v2에선 multi-scale에 더 강인하도록 fc6 layer에서의 atrous conv를 위한 확장 계수를 아래와같이 6, 12, 18, 24로 적용하고 그 결과를 취합(concat)하여 사용함

<center>
<figure>
<img src="/assets/post_img/papers/2019-07-10-deeplab/fig5.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 























