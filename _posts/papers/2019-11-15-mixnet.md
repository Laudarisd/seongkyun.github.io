---
layout: post
title: MixConv：Mixed Depthwise Convolutional Kernels
category: papers
tags: [Deep learning]
comments: true
---

# MixConv：Mixed Depthwise Convolutional Kernels

Original paper: https://arxiv.org/pdf/1907.09595.pdf

Authors: Mingxing Tan, Quoc V. Le (Google brain)

- 참고 글
  - https://www.youtube.com/watch?v=252YxqpHzsg&feature=youtu.be
  - https://www.slideshare.net/JinwonLee9/pr183-mixnet-mixed-depthwise-convolutional-kernels
  - https://medium.com/@tantara/mixnet-on-tensorflow-lite-94520a89b791

## Introduction
- 최근 convolution network design의 트렌드는 네트워크의 정확도와 효율을 모두 높히는 방향으로 연구가 활발히 진행되고 있음
- 이로 인해 다양한 종류의 depthwise convolution들이 연구되어 최근의 CNN모델들에 적용되고 있는 추세
  - MobileNets, ShuffleNets, NASNets, AmoebaNet, MnasNet, EfficientNet 등등
  - 대부분의 모델들에서 depthwise convolution들을 사용함
- 예전의 CNN들은 주로 3x3 conv layer들을 많이 사용했지만, 최근엔 5x5나 7x7같이 큰 커널 사이즈를 갖는 conv layer들을 많이 사용함
  - __큰 커널을 사용하는것이 모델의 정확도나 효율 관점에서 더 좋다는 연구결과들이 있음__

- 본 논문에선 __"큰 커널을 사용할수록 정확도가 향상되나?"__ 라는 fundamental한 질문을 던졌음
  - Conv layer에서 큰 크기의 커널을 사용할경우 파라미터나 연산량이 증가하더라도 더 디테일한 high-resolution pattern들을 학습할 수 있게 됨
  - 반면 작은 크기의 커널을 사용할 경우 low-resolution 패턴을 학습하게 됨
  - 이로 인해 큰 크기의 커널을 사용할수록 네트워크가 더 정확하게 동작 할 수 있게 됨
  - 저자들은 커널 크기가 계속 커질수록 정확도도 계속 높아질것인가에 대한 질문을 한 것임

<center>
<figure>
<img src="/assets/post_img/papers/2019-11-15-mixnet/fig1.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 위 그림에서 왼쪽은 MobileNet v1의 ImageNet Top-1 정확도 결과를, 오른쪽은 MobileNet v2의 정확도 결과를 보여줌
  - x축은 커널 크기, y축은 정확도를 의미
- 그림에서 보이는것처럼 커널 크기가 커지더라도 일정 수준 이상으로 커지게 되면 오히려 정확도가 감소하게 되는 것을 확인 할 수 있음
  - MobileNet v1의 경우 7x7 커널 크기를 썼을 때 가장 성능이 좋았으며, v2의 경우 9x9가 가장 이상적인 커널 크기

- 커널의 크기가 input resolution까지 커지는 극단적인 경우를 생각해보면 이는 마치 fully-connected network처럼 동작하는것과 같게 됨
  - 입력 영상의 각 픽셀(값)과 커널 파라미터가 1:1 매칭되기때문에 fc layer와 동일함
  - __따라서 커널 크기가 extreme하게 계속 커지는것은 성능향상에 도움이 될 수 없음!__
    - 위 실험결과를 볼 때, 각 네트워크들은 해당 네트워크 구조가 갖는 optimal한 커널 크기 point가 존재함
- 따라서 __정확도와 효율의 향상을 위해선 high-resolution 패턴을 학습할 수 있게 해주는 큰 크기의 커널과 low-resolution 패턴을 학습 할 수 있게 해주는 작은 크기의 커널 모두 필요__

## Related Work
### Efficient ConvNets
- 최근들어서 CNN의 효율을 높히기 위한 다양한 연구들이 수행됨
- 특히 mobile-size CNN들에서 depthwise convolution의 인기가 매우 높음
- 일반적인 regular convolution과 다르게, depthwise convolution(=channel-wise convolution)은 각각 채널별로 다른 커널을 이용해 conv 연산을 수행하므로 파라미터 사이즈와 연산량을 줄일 수 있음
  - Regular conv는 $k\times k\times c\times n$개의 파라미터를 이용해 $w\times h\times n$ 크기의 feature map을 생성
    - k: kernel size, c: channel, n: output channel
    - 자세한 내용은 후술
  - Depthwise conv는 $k\times k\times 1\times c$개의 파라미터를 이용해 $w\times h\times c$ 크기의 feature map을 생성
    - 크기를 regular conv와 동일하게 할 경우, 위 연산 후 poin-wise conv로 채널수만 n으로 맞춰주면 됨
    - 이게 MobileNets의 depth-wise separable conv로, 추가되는 파라미터는 $w\times h\times c\times n$개로, 출력 크기는 regular와 같아지지만 실제 연산량 및 파라미터 수는 크게 감소
      - $k\times k\times 1\times c+w\times h\times c\times n$
    - 자세한 내용은 후술

### Multi-Scale Networks and Features
- 이미 multi-branch 구조를 갖는 Inception 계열, Inception-ResNet, ResNext, NASNet등의 CNN들이 다양하게 제안되어왔음
- 각 layer에서 multi-branch 구조를 사용함에 따라 단일 convolution layer에서 다양한 연산(다양한 크기의 커널)을 적용시키는게 가능해짐
- 유사하게 DenseNet이나 FPN(feature pyramid network)등에선 서로 다른 layer들에서 생성된 feature map들을 묶어 multi-scale feature map을 만들어 사용함
  - 위 구조는 multi-branch 구조가 아니라 skip-connection과 같이 input을 네트워크의 다른부분에서 가져와서 concat해 multi-scale feature map을 생성시킴
- 대부분 기존의 연구들은 이처럼 네트워크의 주된 구조(macro-architecture)를 변경/변형하는 식으로 다양한 conv 연산들을 활용함
- __본 논문에선 네트워크 구조를 그대로 주고, 그 구조 안에서 약간의 변형을 적용시켜 기존의 network들을 좀 더 효율적이게 만드는 방법에 대해 연구함__

### Neural Architecture Search
- AutoML, NAS
- 최근엔 사람이 만든(hand-crafted) 모델들보다 NAS를 이용해 만든 네트워크들의 성능이 훨씬 좋음
  - 네트워크 디자인을 자동화하고 알아서 (사람이 지정해준 기준에 따라)더 나은 디자인을 선택하도록 하기 때문
- 새로운 연산이 추가될 경우, NAS의 search space에 추가해주면 NAS가 알아서 최적의 구조를 찾아줌
  - __논문의 저자들도 제안하는 conv 방식(MDConv)을 search space에 추가하고, 효율성과 정확도를 높히는 방향으로 NAS가 최적의 네트워크 구조를 찾도록 했으며, 이를 MixNets(S, M, L)로 정의함__
  
### Regular(Normal) Convolution

<center>
<figure>
<img src="/assets/post_img/papers/2019-11-15-mixnet/fig2.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 일반적인 경우로, output channel인 n개만큼의 커널들을 이용해 sliding window로 구해진 feature map을 만들어내는 과정
  - 위 그림에서 순서대로 input, kernels(weight parameters), output feature map

### Dilated(Atrous) Convolution

<center>
<figure>
<img src="/assets/post_img/papers/2019-11-15-mixnet/fig3.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 일반적인 convolution과 동일하지만 dilation rate를 조절해 파라미터 증가 없이/혹은 최소화하여 conv의 receptive field(RF)를 늘릴 수 있음
  - 주로 image segmenataion에서 많이 사용함

### Group(ed) Convolution

<center>
<figure>
<img src="/assets/post_img/papers/2019-11-15-mixnet/fig4.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>

- Input의 channel을 몇 개의 토막으로 나눠서 연산해 feature map을 만드는 경우
- 위 그림은 group=2인 경우이며, 각 group에 대해 최종 결과는 생성된 feature map들을 concat해 완성됨
- AlexNet이 GPU 메모리때문에 채널을 나눠서 연산을 했는데, 나중에 보니 이로인한 정확도 향상이 유의미했기때문에 ResNeXt나 ShuffleNet 등에서도 사용된 방법

### Depthwise(Channel-wise) Convolution

<center>
<figure>
<img src="/assets/post_img/papers/2019-11-15-mixnet/fig5.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>

- Group convolution에서 group 수= input 채널 수, filter 수 = input 채널 수 인 경우와 동일함
- 각 커널들은 depth 방향으로 1의 크기만을 갖고, 각 채널별로 연산되 만들어진 feature map들이 depth(channel) 방향으로 concat되어 최종 결과 feature map이 완성됨

<center>
<figure>
<img src="/assets/post_img/papers/2019-11-15-mixnet/fig6.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 위 그림처럼 filter 개수를 조절해서 출력 채널 수를 늘릴 수 있음
  - Regular conv와 동일한 크기의 feature map을 만들게 하려면 depthwise conv에서 kernel들을 depth(channel)방향으로 원하는만큼만 쌓으면 됨
  - 연산량과 파라미터수 측면에서 동일 크기의 feature map을 만들 때 훨씬 이점이 큰 방식

### Mixed Depthwise Convolution (MDConv)
- 본 논문에서 제안하는 방식으로, depthwise conv에서 다양한 크기의 커널을 써서 depthwise conv를 수행함
  - 자세한 내용은 후술

## Vanilla Depthwise Convolution

<center>
<figure>
<img src="/assets/post_img/papers/2019-11-15-mixnet/fig7.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>



