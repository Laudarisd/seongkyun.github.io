---
layout: post
title: Feature Pyramid Networks for Object Detection
category: papers
tags: [Deep learning]
comments: true
---

# Feature Pyramid Networks for Object Detection

Original paper: https://arxiv.org/abs/1612.03144

Authors: Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie (Facebook, Cornell Univ.)

- 참고 글
  - https://eehoeskrap.tistory.com/300
  - https://medium.com/@lsrock125/feature-pyramid-networks-for-object-detection-%EB%85%BC%EB%AC%B8%EC%9D%BD%EA%B8%B0-e4e577c4b423
  - https://hwkim94.github.io/deeplearning/cnn/image-detection/fpn/paperreview/2018/10/01/FPN1.html

## Introduction
- Object detection 분야에서 Scale-Invariant는 아주 중요한 문제
  - Scale과 location에 상관없이 객체를 하나의 class로 탐지해야 하기 때문
- 예전에는 다양한 크기의 물체를 탐지하기 위해 이미지 자체의 크기를 resize하면서 물체를 찾았음
  - Pooling이나 stride convolution으로 feature map의 size를 조절하여 detection layer로 객체를 탐지
    - SSD, RFB 등의 기존의 1-stage method들
  - 이러한 작업은 메모리 및 시간 측면에서 비효율적
- 이를 개선하기 위해 Feature Pyramid Network(FPN) 이라는 방법이 등장

## Related Work
### Featurized Image Pyramid

<center>
<figure>
<img src="/assets/post_img/papers/2019-12-06-fpn/fig1.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 각 feature map level에서 독립적으로 특징을 추출해 객체를 탐지하는 방법
- 연산량과 시간 관점에서 비효율적이며 practical하게 적용하기 어려움

### Single Feature Map

<center>
<figure>
<img src="/assets/post_img/papers/2019-12-06-fpn/fig2.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 이 방법은 convolution layer가 scale variant에 robust한 점을 이용하는 방법
  - 이로 인해 Conv layer를 통해 feature를 압축하는 방식
- 하지만 multi scale을 사용하지 않고 한 번에 feature를 압축하여 마지막에 압축된 feature만을 사용
  - 성능이 떨어짐
- YOLO V1에서 사용하는 방법

### Pyramidal Feature Hierarchy

<center>
<figure>
<img src="/assets/post_img/papers/2019-12-06-fpn/fig3.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 서로 다른 scale의 feature map을 이용해 multi scale feature를 추출하는 방식
- 각 level에서 독립적으로 feature를 추출해 객체를 탐지함
  - 이 과정에서 이미 생성된 상위 level의 feature map을 재사용하지 않음
- 대표적으로 SSD에서 사용하는 방식

## Feature Pyramid Network (FPN)
- Top-down 방식으로 feature를 추출함
  - 각 추출된 결과물인 feature map의 low-resolution 및 high-resolution feature들을 묶는 방식
- 각 level에서 독립적으로 feature를 추출해 객체를 탐지함
  - 이 과정에서 상위 level에서 이미 생성된 feautre map을 재사용하므로 multi-scale feature들을 효율적으로 재사용 가능함

<center>
<figure>
<img src="/assets/post_img/papers/2019-12-06-fpn/fig4.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- CNN 자체가 layer를 거치면서 pyramid 구조를 만들고, forward pass를 거치면서 feature map은 더 많은 semantic 정보를 갖는 feature를 얻게 됨
  - 각 level마다 prediction 과정을 넣어서 scale 변화에 더 강인한 모델이 됨

- FPN은 skip connection, top-down, CNN forward pass 과정에서 생성되는 pyramid의 구조를가짐
  - Forward pass에서 생성된 feature map들을 top-down 과정에서 upsampling하여 spatial resolution을 올리고
  - Forward pass에서 손실된 localization feature들을 skip-connection을 이용해 보충
  - 위의 과정을 통해 scale variant에 강인한 feature map을 생성 할 수 있게 됨

- FPN은 ConvNet의 피라미드 계층 구조를 활용함
  - 피라미드 특징 계층 구조는 낮은 수준에서 높은 수준까지의 semantic feature들을 모두 갖고 있음
- 이로 인해 전반적으로 높은 수준의 semantic information을 포함하는 feature pyramid를 생성하게 됨
- 이 FPN은 Fast R-CNN과 Faster R-CNN의 Region Proposal Network (RPN)을 기반으로 함

- FPN은 입력으로 임의 크기의 단일 scale 영상을 입력받음
  - 전체적으로는 conv layer를 통해 비례된 크기의 feature map을 multi-level로 출력하게 됨
  - 이러한 feature concat process는 backbone network와 독립적으로 진행됨
    - 논문에선 ResNet을 backbone으로 사용함
- 위의 과정을 크게 Bottom-up과 Top-down 프로세스로 설명

### Bottom-up pathway





