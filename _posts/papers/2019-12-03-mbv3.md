---
layout: post
title: Searching for MobileNetV3
category: papers
tags: [Deep learning]
comments: true
---

# Searching for MobileNetV3

Original paper: https://arxiv.org/pdf/1905.02244.pdf

Authors: Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, Hartwig Adam (Google)

## Abstract
- 새로운 아키텍쳐를 적용시키는 등의 여러 상호 보완적인 기술들을 조합해서 MobileNet v3를 제안
- MobileNet v3는 mobile phone CPU에 최적화되어있음
  - NetAdapt와 NAS를 조합해서 새로운 구조를 제안
- 본 논문에서는 automated search 알고리즘과 네트워크 디자인이 어떻게 같이 동작해서 전체적인 SOTA 성능을 달성하는지에 대한 보완적인 방법들을 다룸
- 그 과정에서 MobileNetV3-Large와 MobileNetV3-Small이라는 모델을 제안함
  - Large는 high resource 사용시, Small은 low resource 사용시
- 위 두 모델들은 Object detection과 Semantic segmentation에 적용되어 테스트 됨
- Semantic segmentation(or any dense pixel prediction)에서는 효율적인 새로운 segmentation decoder인 Lite Reduced Atrous Spatial Pyramid Pooling (LR-ASPP)를 제안함
- Mobile환경에서의 classification, detection, segmentation task에서 SOTA 성능을 달성했음
- MobileNetV3-Large는 MobileNetV2에 비해 ImageNet classification에서 3.2% 정확하면서도 20%의 latency가 개선됨
- MobileNetV3-Small은 MobileNetV2에 비해 비슷한 latency로 6.6% 더 정확했음
- MobileNetV3-Large는 MobileNetV2에 비해 MS COCO detection에서 25% 빠르면서도 비슷한 정확도를 보였음
- MobileNetV3-Large LR-ASPP는 MobileNetV2 R-ASPP에 비해 Cityspace segmentation에서 34% 빠르면서도 비슷한 정확도를 보였음



<center>
<figure>
<img src="/assets/post_img/papers/2019-12-03-mbv3/fig1.PNG" alt="views">
<figcaption></figcaption>
</figure>
</center>
